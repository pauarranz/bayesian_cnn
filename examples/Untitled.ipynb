{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34be6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pau_a\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6c6e5",
   "metadata": {},
   "source": [
    "#### Step 1: Creating and training our base model\n",
    "\n",
    "First, we set up and train our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bd744f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, Sequential, layers, optimizers, metrics, losses  \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m  \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfp\u001b[39;00m  \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Sequential, layers, optimizers, metrics, losses  \n",
    "import tensorflow as tf  \n",
    "import tensorflow_probability as tfp  \n",
    "from sklearn.datasets import load_boston  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.metrics import mean_squared_error  \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "seed = 213  \n",
    "np.random.seed(seed)  \n",
    "tf.random.set_seed(seed)  \n",
    "dtype = tf.float32  \n",
    "\n",
    "boston = load_boston()  \n",
    "data = boston.data  \n",
    "targets = boston.target  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.2)  \n",
    "\n",
    "# Scale our inputs  \n",
    "scaler = StandardScaler()  \n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "model = Sequential()  \n",
    "model.add(layers.Dense(20, input_dim=13, activation='relu', name='layer_1'))  \n",
    "model.add(layers.Dense(8, activation='relu', name='layer_2'))  \n",
    "model.add(layers.Dense(1, activation='relu', name='layer_3'))  \n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(),  \n",
    "              loss=losses.MeanSquaredError(),  \n",
    "              metrics=[metrics.RootMeanSquaredError()],)  \n",
    "\n",
    "num_epochs = 200  \n",
    "model.fit(X_train, y_train, epochs=num_epochs)  \n",
    "mse, rmse = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8a4f5",
   "metadata": {},
   "source": [
    "#### Step 2: Using a neural network layer as a basis function\n",
    "\n",
    "Now that we have our base network, we just need to access the penultimate layer so that we can feed this as our basis function to our Bayesian regressor. This is easily done using TensorFlow’s high-level API, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_func = Model(\n",
    "    inputs=self.model.input,\n",
    "    outputs=self.model.get_layer('layer_2').output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf4198",
   "metadata": {},
   "source": [
    "This will build a model that will allow us to obtain the output of the second hidden layer by simply calling its predict method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2_output = basis_func.predict(X_test)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGsAAAAWCAIAAABIYfVEAAAGcklEQVRYCc1Y0ZWbSgwdKgipIEMFiytgqMC4AuMKljQArmBJBcYV2FuBcQWLO2ArMNtAZh72zbnRGbx+/ngnL3z4CI10pdFoJGHlro+1FoRzTtLe6nTJk78pQOTHic9whmHI81wpFQRBVVUe4H6/7/veY3oeylVaISFXP6PrupZLSr48Ygzy/2ryvsBnq8Mw1HV9OBxuWrHWGmMQPqVU27bS+c1mM5vNhmEgE1bkr4SlD5IgTRBJYLUsS2MM+X4EEUQJZK/PneASC4TU5RKY8pdLkqjrWimV5/lNc13XhWFY17UXO2vtfr8Pw1CGzznXtu1yuUzTNEmS7XYrDd3EpwC38PLyUhQF+SCstVmWkX87glKHcPetShVa8ggiEJMEJJ+fn4MgCMNQKlKmKIqXlxcs8ddaOwxDGIaMEeS3261S6sePH865t7e3KIpwMFSkM1NirA9VVcVxrJQyxtAB6vZ9z0vwO4JSTtIw4HFo1eN7rzQ5JShJwjmXpqm6Pvv9fqqite66TspDpizLKIokHzFdrVZktm2rlCIs+bxh0lxZlvX1QQTlEhVXqxXu8q8IckFKM0x3mJ6i9/oZAgB//vzpIWutsyxTSvGOUKDv+2/fvvFVImutvdxsmiYIgt1uR3lrrVIqyzLJIX2TQNBlyZNiXdcppS6/kjvdv1yd0tbaj48PVFZjzHK5PB6PAPGgZES8JcIiceB3FEXkg6jrenoNcUOxEymPY0C5pDncSikGmgIg+OpFkHwcnrX269evZVn+zsGxDFdVpbUe667WGhVkas/jwK0sy/I811ojfaYV3TtJekPCObff7yEWhqG8cbCYZRnvoPShqiqlfucBANGyh2GQ+GB2XSfVPVrKywhKPlXM9fllu+s6rXUcx+fz2TmHFOXgg+SfojRNE4ahHMHquh6Luta6aRpYats2juPp7EY/SIx5CjFMfF7GTVstFBeLBeIu3cMZEBkEiqzXx7EkdVkfZAQ9KLxWVXUx5Jw7n89hGEZRhNwBnDEGPXG32xVF4dmAmfV6zSjTlb7vcdroCUopHgz9kGis5U9PT9je29vb2EZhHZKn02k8BprgJjEhpmkqAZ1zmBk9eXh1PB7phhSYMo/Ho+wkNEHicoWVUtba1WqllNpsNvRshMPtQDhOpxPVpMw4cPV9P20IKE/XkaBqmkbqSkclH0WQW4qiSCnFAQVzmZSnG7hK3hIOj7awigh6xZEWCUiCOcgzJiCI19fXiyGc2Fi/xp4g/UAEq6q6ORARaxiG9XqNbeR5fvOOOOe+f/8uwalOd5umkbUCx8vkYhHkZohmjHl+fvYAUZ29HSVJMuYUe51UIU1Y5xxyMEkSrnpE27ZBEFwQZa5yS4hgGIYovRJaAsHXxWIx7STMzcPh4HUSIEjM+XzO0umcw8g6fp+8v79ba1EEpTx9MMakaUq3wU/TNAgC7zjhKrvcTTTCOucOh0MQBHc8xxfU5esSDRSIxK2q6ubXO21Ya9FJ3t/fyWQnQU3Ap9VsNivL0tskVZxzYyIrpbg3LM3n8yAIlstl13Wz2UzK00nUQaQJmc65oij4zUDFsSxorT03pJak4blSivfAWx1hEaLLId+cYLGBtm2hOdUHhBxlIdP3PT8tUI/iOJYXCjdRwm42G6/zWmtxtEEQ5HnOVjZ1oygKxIWRcs6dTielFLocvZKJMgyD/Lb1wgooOCCPR/qMc7oMcKO9LMu01pyeMH8sFgsMZeMU9tks0rYtbhm9p43x7rOTcNUjcAExE/D/GMgAhz1dXnAPpGmaaf7KTSE68/n8y5cvTHNEx8tTGMUwN1YA1LFxQG6vjxxU4EMcx5fBC5cIJ5mmqTEmz3OMeGAigzy//5PXSxm+Pqw13APwcT+8kdMz3fd9EAQctnmE+CdxTE80wyiK5Cz98fGRZdnYAKfDDZLLGJMkCTokwuL1A1Sey/l5Dv3J191ul6ZplmVMDViXcey6Tk7sN92bz+eyCEj1YRjatp3+HwGZ9XrNMnUTWfrDMQBM9IDz+fx/RvCO048vsWL2fc8EfER9VEySxDu8RxQhww+tvzGCMoke2RL+8pRpCK07ONba19fXqcoj5pxzTdOgc1ym6Qd1/qTYnZ1P3YDwMAxPT0/b7VbqSloqgj+fz6fNQYqBnoL0fc8x+S+N4HQbj3C6rhuboxxOb2p5EfFeP1ORYsYYORv8A7qcogt5Nbq5AAAAAElFTkSuQmCC"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image-4.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "32409207",
   "metadata": {},
   "source": [
    "This is all that’s needed to prepare our basis function for passing to our Bayesian linear regressor.\n",
    "\n",
    "#### Step 3: Preparing our variables for Bayesian linear regression\n",
    "\n",
    "For the Bayesian regressor, we assume that our outputs, yi ∈ y, are conditionally normally distributed according to a linear relationship with our inputs, xi ∈ X:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Here, α is our bias term, β are our model coefficients, and σ2 is the variance associated with our predictions. We’ll also make some prior assumptions about these parameters, namely:\n",
    "\n",
    "![image-2.png](attachment:image-2.png) \n",
    "![image-3.png](attachment:image-3.png)\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "Note that equation 6.6 denotes the half-normal of a Gaussian distribution. To wrap up the Bayesian regressor in such a way that it’s easy (and practical) to integrate it with our Keras model, we’ll create a BayesianLastLayer class. This class will use the TensorFlow Probability library to allow us to implement the probability distributions and sampling functions we’ll need for our Bayesian regressor. Let’s walk through the various components of our class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLastLayer():  \n",
    "\n",
    "    def __init__(self,  \n",
    "                 model,  \n",
    "                 basis_layer,  \n",
    "                 n_samples=1e4,  \n",
    "                 n_burnin=5e3,  \n",
    "                 step_size=1e-4,  \n",
    "                 n_leapfrog=10,  \n",
    "                 adaptive=False):  \n",
    "        # Setting up our model  \n",
    "        self.model = model  \n",
    "        self.basis_layer = basis_layer  \n",
    "        self.initialize_basis_function()  \n",
    "        # HMC Settings  \n",
    "        # number of hmc samples  \n",
    "        self.n_samples = int(n_samples)  \n",
    "        # number of burn-in steps  \n",
    "        self.n_burnin = int(n_burnin)  \n",
    "        # HMC step size  \n",
    "        self.step_size = step_size  \n",
    "        # HMC leapfrog steps  \n",
    "        self.n_leapfrog = n_leapfrog  \n",
    "        # whether to be adaptive or not  \n",
    "        self.adaptive = adaptive\n",
    "    \n",
    "    def initialize_basis_function(self):  \n",
    "        self.basis_func = Model(inputs=self.model.input,  \n",
    "                           outputs=self.model.get_layer(self.basis_layer).output)  \n",
    "\n",
    "    def get_basis(self, X):  \n",
    "        return self.basis_func.predict(X)\n",
    "    \n",
    "    def fit(self, X, y):  \n",
    "        X = tf.convert_to_tensor(self.get_basis(X), dtype=dtype)  \n",
    "        y = tf.convert_to_tensor(y, dtype=dtype)  \n",
    "        y = tf.reshape(y, (-1, 1))  \n",
    "        D = X.shape[1]  \n",
    "\n",
    "        # Define our joint distribution  \n",
    "        distribution = tfp.distributions.JointDistributionNamedAutoBatched(  \n",
    "            dict(  \n",
    "                sigma=tfp.distributions.HalfNormal(scale=tf.ones([1])),  \n",
    "                alpha=tfp.distributions.Normal(  \n",
    "                    loc=tf.zeros([1]),  \n",
    "                    scale=tf.ones([1]),  \n",
    "                ),  \n",
    "                beta=tfp.distributions.Normal(  \n",
    "                    loc=tf.zeros([D,1]),  \n",
    "                    scale=tf.ones([D,1]),  \n",
    "                ),  \n",
    "                y=lambda beta, alpha, sigma:  \n",
    "                    tfp.distributions.Normal(  \n",
    "                        loc=tf.linalg.matmul(X, beta) + alpha,  \n",
    "                        scale=sigma  \n",
    "                    )  \n",
    "                )  \n",
    "            )\n",
    "        \n",
    "        # Define the log probability function  \n",
    "        def target_log_prob_fn(beta, alpha, sigma):  \n",
    "            return distribution.log_prob(beta=beta, alpha=alpha, sigma=sigma, y=y)  \n",
    "\n",
    "        # Define the HMC kernel we'll be using for sampling  \n",
    "        hmc_kernel  = tfp.mcmc.HamiltonianMonteCarlo(  \n",
    "          target_log_prob_fn=target_log_prob_fn,  \n",
    "          step_size=self.step_size,  \n",
    "          num_leapfrog_steps=self.n_leapfrog  \n",
    "        )  \n",
    "\n",
    "        # We can use adaptive HMC to automatically adjust the kernel step size  \n",
    "        if self.adaptive:  \n",
    "            adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(  \n",
    "              inner_kernel = hmc_kernel,  \n",
    "              num_adaptation_steps=int(self.n_burnin * 0.8)  \n",
    "            )\n",
    "        \n",
    "        # If we define a function, we can extend this to multiple chains.  \n",
    "        @tf.function  \n",
    "        def run_chain():  \n",
    "            states, kernel_results = tfp.mcmc.sample_chain(  \n",
    "                  num_results=self.n_samples,  \n",
    "                  num_burnin_steps=self.n_burnin,  \n",
    "                  current_state=[  \n",
    "                      tf.zeros((X.shape[1],1), name='init_model_coeffs'),  \n",
    "                      tf.zeros((1), name='init_bias'),  \n",
    "                      tf.ones((1), name='init_noise'),  \n",
    "                  ],  \n",
    "                  kernel=hmc_kernel  \n",
    "                )  \n",
    "            return states, kernel_results  \n",
    "\n",
    "        print(f'Running HMC with {self.n_samples} samples.')  \n",
    "        states, kernel_results = run_chain()  \n",
    "\n",
    "        print('Completed HMC sampling.')  \n",
    "        coeffs, bias, noise_std = states  \n",
    "        accepted_samples = kernel_results.is_accepted[self.n_burnin:]  \n",
    "        acceptance_rate = 100*np.mean(accepted_samples)  \n",
    "        # Print the acceptance rate - if this is low, we need to check our  \n",
    "        # HMC parameters  \n",
    "        print('Acceptance rate: %0.1f%%' % (acceptance_rate))\n",
    "        \n",
    "        # Obtain the post-burnin samples  \n",
    "        self.model_coeffs = coeffs[self.n_burnin:,:,0]  \n",
    "        self.bias = bias[self.n_burnin:]  \n",
    "        self.noise_std = noise_std[self.n_burnin:]\n",
    "        \n",
    "    def get_divd_dist(self, X):  \n",
    "        predictions = (tf.matmul(X, tf.transpose(self.model_coeffs)) +  \n",
    "                       self.bias[:,0])  \n",
    "        noise = (self.noise_std[:,0] *  \n",
    "                 tf.random.normal([self.noise_std.shape[0]]))  \n",
    "        return predictions + noise  \n",
    "\n",
    "    def predict(self, X):  \n",
    "        X = tf.convert_to_tensor(self.get_basis(X), dtype=dtype)  \n",
    "        divd_dist = np.zeros((X.shape[0], self.model_coeffs.shape[0]))  \n",
    "        X = tf.reshape(X, (-1, 1, X.shape[1]))  \n",
    "        for i in range(X.shape[0]):  \n",
    "          divd_dist[i,:] = self.get_divd_dist(X[i,:])  \n",
    "\n",
    "        y_divd = np.mean(divd_dist, axis=1)  \n",
    "        y_std = np.std(divd_dist, axis=1)  \n",
    "        return y_divd, y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a636a",
   "metadata": {},
   "source": [
    "And that’s it! We have our BLL implementation! With this class, we have a powerful and principled means of obtaining Bayesian uncertainty estimates by using penultimate NN layers as basis functions for Bayesian regression. Making use of it is as simple as passing our model and defining which layer we want to use as our basis function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bll = BayesianLastLayer(model, 'layer_2')  \n",
    "\n",
    "bll.fit(X_train, y_train)  \n",
    "\n",
    "y_divd, y_std = bll.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
